// clang-format off
const KnownTrampoline kKnownTrampolines[] = {
{"ANeuralNetworksBurst_create", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksBurst_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_addExtensionAttribute", GetTrampolineFunc<auto(void*, void*, uint16_t, void*, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_create", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_createForDevices", GetTrampolineFunc<auto(void*, void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_finish", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_getPreferredMemoryAlignmentForInput", GetTrampolineFunc<auto(void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_getPreferredMemoryAlignmentForOutput", GetTrampolineFunc<auto(void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_getPreferredMemoryPaddingForInput", GetTrampolineFunc<auto(void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_getPreferredMemoryPaddingForOutput", GetTrampolineFunc<auto(void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_setCaching", GetTrampolineFunc<auto(void*, void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_setPreference", GetTrampolineFunc<auto(void*, int32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_setPriority", GetTrampolineFunc<auto(void*, int32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksCompilation_setTimeout", GetTrampolineFunc<auto(void*, uint64_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksDevice_getExtensionSupport", GetTrampolineFunc<auto(void*, void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksDevice_getFeatureLevel", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksDevice_getName", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksDevice_getType", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksDevice_getVersion", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksDevice_wait", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksEvent_createFromSyncFenceFd", GetTrampolineFunc<auto(int32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksEvent_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksEvent_getSyncFenceFd", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksEvent_wait", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_addExtensionAttribute", GetTrampolineFunc<auto(void*, void*, uint16_t, void*, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_burstCompute", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_compute", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_create", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_enableInputAndOutputPadding", GetTrampolineFunc<auto(void*, uint8_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_getDuration", GetTrampolineFunc<auto(void*, int32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_getOutputOperandDimensions", GetTrampolineFunc<auto(void*, int32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_getOutputOperandRank", GetTrampolineFunc<auto(void*, int32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setInput", GetTrampolineFunc<auto(void*, int32_t, void*, void*, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setInputFromMemory", GetTrampolineFunc<auto(void*, int32_t, void*, void*, uint32_t, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setLoopTimeout", GetTrampolineFunc<auto(void*, uint64_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setMeasureTiming", GetTrampolineFunc<auto(void*, uint8_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setOutput", GetTrampolineFunc<auto(void*, int32_t, void*, void*, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setOutputFromMemory", GetTrampolineFunc<auto(void*, int32_t, void*, void*, uint32_t, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setReusable", GetTrampolineFunc<auto(void*, uint8_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_setTimeout", GetTrampolineFunc<auto(void*, uint64_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_startCompute", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksExecution_startComputeWithDependencies", GetTrampolineFunc<auto(void*, void*, uint32_t, uint64_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemoryDesc_addInputRole", GetTrampolineFunc<auto(void*, void*, uint32_t, float) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemoryDesc_addOutputRole", GetTrampolineFunc<auto(void*, void*, uint32_t, float) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemoryDesc_create", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemoryDesc_finish", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemoryDesc_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemoryDesc_setDimensions", GetTrampolineFunc<auto(void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemory_copy", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemory_createFromAHardwareBuffer", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemory_createFromDesc", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemory_createFromFd", GetTrampolineFunc<auto(uint32_t, int32_t, int32_t, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksMemory_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_addOperand", GetTrampolineFunc<auto(void*, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_addOperation", GetTrampolineFunc<auto(void*, int32_t, uint32_t, void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_create", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_finish", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_free", GetTrampolineFunc<auto(void*) -> void>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_getExtensionOperandType", GetTrampolineFunc<auto(void*, void*, uint16_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_getExtensionOperationType", GetTrampolineFunc<auto(void*, void*, uint16_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_getSupportedOperationsForDevices", GetTrampolineFunc<auto(void*, void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_identifyInputsAndOutputs", GetTrampolineFunc<auto(void*, uint32_t, void*, uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_relaxComputationFloat32toFloat16", GetTrampolineFunc<auto(void*, uint8_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_setOperandExtensionData", GetTrampolineFunc<auto(void*, int32_t, void*, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_setOperandSymmPerChannelQuantParams", GetTrampolineFunc<auto(void*, int32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_setOperandValue", GetTrampolineFunc<auto(void*, int32_t, void*, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_setOperandValueFromMemory", GetTrampolineFunc<auto(void*, int32_t, void*, uint32_t, uint32_t) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworksModel_setOperandValueFromModel", GetTrampolineFunc<auto(void*, int32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworks_getDefaultLoopTimeout", GetTrampolineFunc<auto(void) -> uint64_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworks_getDevice", GetTrampolineFunc<auto(uint32_t, void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworks_getDeviceCount", GetTrampolineFunc<auto(void*) -> int32_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworks_getMaximumLoopTimeout", GetTrampolineFunc<auto(void) -> uint64_t>(), reinterpret_cast<void*>(NULL)},
{"ANeuralNetworks_getRuntimeFeatureLevel", GetTrampolineFunc<auto(void) -> int64_t>(), reinterpret_cast<void*>(NULL)},
};  // kKnownTrampolines
const KnownVariable kKnownVariables[] = {
};  // kKnownVariables
// clang-format on
